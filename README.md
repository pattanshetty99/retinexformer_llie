# RetinexFormer-LLIE  
### Joint Low-Light Enhancement and Residual Denoising (Wild Scene Dataset)

This repository implements a **RetinexFormer-style hybrid model** for joint low-light image enhancement and residual denoising.  

It is designed for large-scale datasets (10,000+ images) captured in real-world wild scenes, where perceptual quality is prioritized over pure noise suppression.

---

## ğŸ“Œ Overview

Low-light images often suffer from:
- Illumination imbalance
- Reduced contrast
- Color shifts
- Residual sensor noise

This model follows a **Retinex-based decomposition + Transformer enhancement + lightweight noise refinement** pipeline:

```
Input RGB
    â†“
Retinex Decomposition
    â”œâ”€â”€ Illumination Map
    â””â”€â”€ Reflectance Map
    â†“
Transformer-based Illumination Enhancement
    â†“
Reflectance Noise Refinement
    â†“
Reconstruction (Enhanced RGB)
```

---

## ğŸš€ Features

- Retinex decomposition (Illumination + Reflectance)
- Transformer-based global illumination modeling
- Lightweight residual noise refinement
- Mixed precision (AMP) training
- Resume training support
- Automatic best-model saving
- Training on 10,000-image subset
- Folder-based batch testing
- PSNR & SSIM evaluation

---

## ğŸ“‚ Project Structure

```
retinexformer_llie/
â”‚
â”œâ”€â”€ train.py
â”œâ”€â”€ test.py
â”œâ”€â”€ evaluate.py
â”œâ”€â”€ requirements.txt
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ retinexformer.py
â”‚   â”œâ”€â”€ transformer_block.py
â”‚   â”œâ”€â”€ decomposition.py
â”‚   â”œâ”€â”€ refinement.py
â”‚
â”œâ”€â”€ losses/
â”‚   â”œâ”€â”€ losses.py
â”‚
â”œâ”€â”€ datasets/
â”‚   â”œâ”€â”€ llie_dataset.py
â”‚
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ metrics.py
â”‚
â””â”€â”€ checkpoints/
```

---

## ğŸ›  Installation

### 1ï¸âƒ£ Clone the repository

```bash
git clone https://github.com/your_username/retinexformer_llie.git
cd retinexformer_llie
```

### 2ï¸âƒ£ Create environment

```bash
conda create -n llie python=3.10 -y
conda activate llie
```

### 3ï¸âƒ£ Install dependencies

```bash
pip install -r requirements.txt
```

---

## ğŸ“Š Dataset Structure

Training dataset must be structured as:

```
data/
â”œâ”€â”€ low/
â”œâ”€â”€ high/
â”œâ”€â”€ val_low/
â””â”€â”€ val_high/
```

- `low/` â†’ low-light input images
- `high/` â†’ reference images
- `val_low/` â†’ validation inputs
- `val_high/` â†’ validation references

Images must be paired and sorted consistently.

---

## ğŸ‹ï¸ Training

### Train on 10,000 images

```bash
python train.py
```

If dataset contains more than 10,000 images, a random subset of 10,000 will be used automatically.

### Resume Training

Edit inside `train.py`:

```python
RESUME_PATH = "checkpoints/last.pth"
```

Then run:

```bash
python train.py
```

---

## ğŸ’¾ Checkpoint Saving

- `checkpoints/last.pth` â†’ latest checkpoint (every epoch)
- `checkpoints/best_model.pth` â†’ best model (based on validation PSNR)

Best model is updated automatically when validation PSNR improves.

---

## ğŸ§ª Testing on a Folder

Place test images inside:

```
test_images/
```

Then run:

```bash
python test.py
```

Results will be saved in:

```
results/
```

---

## ğŸ“ˆ Evaluation Metrics

The model is evaluated using:

### ğŸ”¹ PSNR (Peak Signal-to-Noise Ratio)

Measures reconstruction quality relative to ground truth.

Higher is better.

### ğŸ”¹ SSIM (Structural Similarity Index)

Measures structural similarity and perceptual consistency.

Range: 0 â€“ 1  
Higher is better.

---

## ğŸ§  Architecture Details

### Retinex Decomposition

Separates input image into:

- Illumination (brightness information)
- Reflectance (texture & structure)

### Illumination Enhancement

- Multi-head self-attention transformer blocks
- Global context modeling
- Adaptive brightness correction

### Reflectance Refinement

- Lightweight residual CNN
- Removes mild residual noise
- Preserves texture

### Reconstruction

```
Enhanced Output = Enhanced Illumination Ã— Refined Reflectance
```

---

## ğŸ¯ Design Philosophy

This model is designed for:

- Wild-scene low-light datasets
- Mild residual noise
- Perceptual quality optimization
- Competition-level benchmarks

Heavy denoising is intentionally avoided to preserve texture realism.

---

## âš¡ Future Improvements

- Multi-scale transformer
- EMA model tracking
- Distributed training (DDP)
- Cosine learning rate scheduler
- LPIPS perceptual optimization
- Window-based attention (Swin-style)
- Patch-based 512Ã—512 training

---

## ğŸ“œ License

This project is provided for research and academic purposes.

---

## ğŸ‘¤ Author

Your Name  
GitHub: https://github.com/your_username  

---

## â­ If This Helps You

If this repository helps your research or competition submission, please consider giving it a star â­
